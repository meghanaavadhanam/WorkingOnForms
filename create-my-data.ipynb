{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This takes the token file and does a number of things:\n",
    "# - rejects documents with too few tokens (need OCR) or no ground truth\n",
    "# - normalizes page numbers in 0..1\n",
    "# - provides fuzzy matching scores for each token vs ground truth tokens\n",
    "\n",
    "import csv\n",
    "import decimal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "#from util import is_dollar_amount, normalize_dollars\n",
    "\n",
    "output_docs = 0\n",
    "\n",
    "# Data in filings that we want to find.\n",
    "# We output a column for each one of these, indicating how close the token is to\n",
    "# the correct answer.\n",
    "# For our first experiment, just extract gross_amount\n",
    "# Other possible targets include 'committee','agency','callsign'\n",
    "\n",
    "#targets = [\"gross_amount\", \"contract_number\", \"committee\"]\n",
    "targets = [\"Wages, tips and other compensation\", \"Federal Income tax withheld\", \"Social Security wages\", \"Social security tax withheld\"]\n",
    "targets = [t.replace(' ', '_') for t in targets]\n",
    "\n",
    "filings = pd.read_csv(\"C:/Users/HP/Documents/work/DeepForm/deepform-master/myfilings.csv\")\n",
    "\n",
    "incsv = pd.read_csv(\"C:/Users/HP/Documents/work/DeepForm/deepform-master/my-tokens.csv\")\n",
    "\n",
    "outcols = [\"slug\", \"x0\", \"y0\", \"x1\", \"y1\", \"token\"] + targets\n",
    "outcsv = csv.DictWriter(open(\"mytrain.csv\", mode=\"w\", encoding = \"utf-8\"), fieldnames=outcols)\n",
    "outcsv.writeheader()\n",
    "\n",
    "\n",
    "# computes fuzzy distance from each token in the series to the target answer for\n",
    "# the document answer may be multiple tokens, in which case we take the max of\n",
    "# matches.\n",
    "def multi_token_target_match(answer, tokens, target, max_n, anstok):\n",
    "    best_match = [0 for i in range(max_n)]\n",
    "    best_idx = [0 for i in range(max_n)]\n",
    "    # Two dimensional because we will have one array for each possible n-gram length.\n",
    "    ratioslist = np.zeros((max_n, len(tokens)))\n",
    "    # For each possible number of tokens in answertoken:\n",
    "    for i in range(max_n):\n",
    "        # For each n-gram of that length in the doc:\n",
    "        for idx in range(0, len(tokens) - i):\n",
    "            # Make it one token so we can compare.\n",
    "            token_string = \"\".join(str(t) for t in tokens[idx : idx + i + 1])\n",
    "            # Compare and store the float in match.\n",
    "            match = fuzz.ratio(anstok, token_string) / 100.0\n",
    "            # Update the ratioslist matrix with this match value for the n-gram\n",
    "            # length and index.\n",
    "            ratioslist[i, idx] = match\n",
    "            # Update our vector of best matches for each n-gram.\n",
    "            if match > best_match[i]:\n",
    "                best_match[i] = match\n",
    "                best_idx[i] = idx\n",
    "    print(\"best_match array: \" + str(best_match))\n",
    "    best_len = np.argmax(best_match) + 1\n",
    "    best_match_idx = best_idx[best_len - 1]\n",
    "    print(\"Best choice for number of tokens: \" + str(best_len))\n",
    "    print(\n",
    "        \"Best Match Token Sequence: \"\n",
    "        + str(tokens[best_match_idx : best_match_idx + best_len])\n",
    "    )\n",
    "\n",
    "    scores = np.zeros(len(tokens))\n",
    "\n",
    "    # Make a list of all indices from ratioslist[np.argmax(best_match),:] which\n",
    "    # have the best match.\n",
    "    best_idx_list = [\n",
    "        i\n",
    "        for i, value in enumerate(ratioslist[np.argmax(best_match), :])\n",
    "        if value == best_match[best_len - 1]\n",
    "    ]\n",
    "    print(\"Target Occurs at Indices: \" + str(best_idx_list))\n",
    "\n",
    "    # For each of these indices in scores, set the following best_len tokens\n",
    "    # equal to best_match.\n",
    "    for a in best_idx_list:\n",
    "        for i in range(best_len):\n",
    "            scores[a + i] = best_match[best_len - 1]\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def target_match(answer, tokens, target, max_n):\n",
    "    print()\n",
    "    print(\"target: \" + target)\n",
    "    print(\"answer: \" + str(answer))\n",
    "    anstok = (\n",
    "        str(answer).lower().replace(\" \", \"\")\n",
    "    )  # Remove spaces and make the answer lower case\n",
    "    tokens = [token.lower() for token in tokens]  # lowercase all the tokens also\n",
    "\n",
    "    if target == \"Wages, tips and other compensation\":\n",
    "\n",
    "        scores = []\n",
    "        max_n = 1\n",
    "        for token in tokens:\n",
    "            if is_dollar_amount(anstok) and is_dollar_amount(token):\n",
    "                try:\n",
    "                    scores.append(\n",
    "                        fuzz.ratio(normalize_dollars(anstok), normalize_dollars(token))\n",
    "                        / 100.0\n",
    "                    )\n",
    "                except decimal.InvalidOperation:\n",
    "                    # not a number, maybe a date?\n",
    "                    scores.append(fuzz.ratio(anstok, token) / 100.0)\n",
    "            else:\n",
    "                scores.append(fuzz.ratio(anstok, token) / 100.0)\n",
    "\n",
    "    else:\n",
    "        scores = multi_token_target_match(answer, tokens, target, max_n, anstok)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaece6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wages,_tips_and_other_compensation',\n",
       " 'Federal_Income_tax_withheld',\n",
       " 'Social_Security_wages',\n",
       " 'Social_security_tax_withheld']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6901a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc(slug, rows, max_n):\n",
    "    print()\n",
    "    print()\n",
    "    print(\"--------------------------------\")\n",
    "    print(f\"Processing {slug} with {len(rows)} tokens\")\n",
    "    global output_docs\n",
    "    if len(rows) < 10:\n",
    "        # probably needs OCR\n",
    "        print(f\"Skipping {slug} because it has only {len(rows)} tokens\")\n",
    "        return\n",
    "    \n",
    "    filings.columns = [c.replace(' ', '_') for c in filings.columns]\n",
    "    answers = filings[filings.pdf_file.str.contains(slug)]\n",
    "    #answers = filings.loc[filings[\"pdf file\"] == slug]\n",
    "    #answers = filings.loc[filings[\"pdf file\"].intersection(slug)]\n",
    "    \n",
    "    print(\"printing answers here 1\", answers)\n",
    "    \n",
    "    if len(answers) != 1:\n",
    "        print(f\"Skipping {slug} because it matches {len(answers)} rows\")\n",
    "        return\n",
    "    answers = answers.iloc[0]\n",
    "    \n",
    "    print(\"\\n\\n printing answers here 2\\n\\n\", answers)\n",
    "    print(\"type of answers\", type(answers))\n",
    "    \n",
    "    if answers[targets].isnull().any():\n",
    "        print(\n",
    "            f\"Skipping {slug} because it is missing answers for \"\n",
    "            f\"{[t for t in targets if pd.isnull(answers[t])]}\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    '''\n",
    "    page = pd.to_numeric(df[\"page\"])\n",
    "    maxpage = page.max()\n",
    "    if maxpage:  # avoid div/0 for one page docs\n",
    "        df[\"page\"] = page / maxpage  # last page = 1.0\n",
    "    '''\n",
    "    \n",
    "    for t in targets:\n",
    "        df[t] = target_match(\n",
    "            answers[t], df[\"token\"].fillna(\"\"), t, max_n\n",
    "        )  # The value of the answer and an array of the tokens for that slug\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        outcsv.writerow(row.to_dict())\n",
    "\n",
    "    output_docs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d08309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing CAPRUS W2.pdf with 2430 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping CAPRUS W2.pdf because it matches 0 rows\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing DAT W2 (1).pdf with 2575 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping DAT W2 (1).pdf because it matches 0 rows\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing DAT W2-2.pdf with 128 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping DAT W2-2.pdf because it matches 0 rows\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing F5 W2.pdf with 482 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping F5 W2.pdf because it matches 0 rows\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing ISN W2.pdf with 2453 tokens\n",
      "printing answers here 1      pdf_file  Wages,_tips_and_other_compensation  \\\n",
      "2  ISN W2.pdf                           135405.59   \n",
      "\n",
      "   Federal_Income_tax_withheld  Social_Security_wages  \\\n",
      "2                     14431.03               132900.0   \n",
      "\n",
      "   Social_security_tax_withheld  \n",
      "2                        8239.8  \n",
      "\n",
      "\n",
      " printing answers here 2\n",
      "\n",
      " pdf_file                              ISN W2.pdf\n",
      "Wages,_tips_and_other_compensation     135405.59\n",
      "Federal_Income_tax_withheld             14431.03\n",
      "Social_Security_wages                   132900.0\n",
      "Social_security_tax_withheld              8239.8\n",
      "Name: 2, dtype: object\n",
      "type of answers <class 'pandas.core.series.Series'>\n",
      "\n",
      "target: Wages,_tips_and_other_compensation\n",
      "answer: 135405.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_match array: [1.0, 0.72, 0.67]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['135405.59']\n",
      "Target Occurs at Indices: [91, 168, 170, 172]\n",
      "\n",
      "target: Federal_Income_tax_withheld\n",
      "answer: 14431.03\n",
      "best_match array: [1.0, 0.94, 0.62]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['14431.03']\n",
      "Target Occurs at Indices: [92, 169, 171, 173]\n",
      "\n",
      "target: Social_Security_wages\n",
      "answer: 132900.0\n",
      "best_match array: [0.86, 0.7, 0.67]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['132900']\n",
      "Target Occurs at Indices: [97, 186, 188, 190]\n",
      "\n",
      "target: Social_security_tax_withheld\n",
      "answer: 8239.8\n",
      "best_match array: [1.0, 0.92, 0.63]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['8239.8']\n",
      "Target Occurs at Indices: [98, 187, 189, 191]\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing Intel W2.pdf with 192 tokens\n",
      "printing answers here 1        pdf_file  Wages,_tips_and_other_compensation  \\\n",
      "3  Intel W2.pdf                           106468.39   \n",
      "\n",
      "   Federal_Income_tax_withheld  Social_Security_wages  \\\n",
      "3                     16612.21              121169.32   \n",
      "\n",
      "   Social_security_tax_withheld  \n",
      "3                        7512.5  \n",
      "\n",
      "\n",
      " printing answers here 2\n",
      "\n",
      " pdf_file                              Intel W2.pdf\n",
      "Wages,_tips_and_other_compensation       106468.39\n",
      "Federal_Income_tax_withheld               16612.21\n",
      "Social_Security_wages                    121169.32\n",
      "Social_security_tax_withheld                7512.5\n",
      "Name: 3, dtype: object\n",
      "type of answers <class 'pandas.core.series.Series'>\n",
      "\n",
      "target: Wages,_tips_and_other_compensation\n",
      "answer: 106468.39\n",
      "best_match array: [1.0, 0.72, 0.55]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['106468.39']\n",
      "Target Occurs at Indices: [0, 2, 94, 96]\n",
      "\n",
      "target: Federal_Income_tax_withheld\n",
      "answer: 16612.21\n",
      "best_match array: [1.0, 0.64, 0.52]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['16612.21']\n",
      "Target Occurs at Indices: [1, 3, 95, 97]\n",
      "\n",
      "target: Social_Security_wages\n",
      "answer: 121169.32\n",
      "best_match array: [1.0, 0.75, 0.6]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['121169.32']\n",
      "Target Occurs at Indices: [6, 8, 12, 14, 100, 102, 106, 108]\n",
      "\n",
      "target: Social_security_tax_withheld\n",
      "answer: 7512.5\n",
      "best_match array: [1.0, 0.57, 0.44]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['7512.5']\n",
      "Target Occurs at Indices: [7, 9, 101, 103]\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing Oath W2.pdf with 4060 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping Oath W2.pdf because it matches 0 rows\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing OpenLogix W2.pdf with 658 tokens\n",
      "printing answers here 1            pdf_file  Wages,_tips_and_other_compensation  \\\n",
      "0  OpenLogix W2.pdf                             74140.0   \n",
      "\n",
      "   Federal_Income_tax_withheld  Social_Security_wages  \\\n",
      "0                      8886.74                74140.0   \n",
      "\n",
      "   Social_security_tax_withheld  \n",
      "0                       4596.68  \n",
      "\n",
      "\n",
      " printing answers here 2\n",
      "\n",
      " pdf_file                              OpenLogix W2.pdf\n",
      "Wages,_tips_and_other_compensation             74140.0\n",
      "Federal_Income_tax_withheld                    8886.74\n",
      "Social_Security_wages                          74140.0\n",
      "Social_security_tax_withheld                   4596.68\n",
      "Name: 0, dtype: object\n",
      "type of answers <class 'pandas.core.series.Series'>\n",
      "\n",
      "target: Wages,_tips_and_other_compensation\n",
      "answer: 74140.0\n",
      "best_match array: [0.83, 0.74, 0.61]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['74140']\n",
      "Target Occurs at Indices: [153, 162, 195, 247, 256, 289, 342, 351, 380, 540, 549]\n",
      "\n",
      "target: Federal_Income_tax_withheld\n",
      "answer: 8886.74\n",
      "best_match array: [0.43, 0.48, 0.43]\n",
      "Best choice for number of tokens: 2\n",
      "Best Match Token Sequence: ['204088566', '74140']\n",
      "Target Occurs at Indices: [194, 288, 379]\n",
      "\n",
      "target: Social_Security_wages\n",
      "answer: 74140.0\n",
      "best_match array: [0.83, 0.74, 0.61]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['74140']\n",
      "Target Occurs at Indices: [153, 162, 195, 247, 256, 289, 342, 351, 380, 540, 549]\n",
      "\n",
      "target: Social_security_tax_withheld\n",
      "answer: 4596.68\n",
      "best_match array: [1.0, 0.74, 0.38]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['4596.68']\n",
      "Target Occurs at Indices: [154, 248, 343, 541]\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing Qual W2FORM.pdf with 2569 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping Qual W2FORM.pdf because it matches 0 rows\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing Saxon W2.pdf with 4 tokens\n",
      "Skipping Saxon W2.pdf because it has only 4 tokens\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing Sonus Software W2.pdf with 456 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping Sonus Software W2.pdf because it matches 0 rows\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing Stategic Systems W2.pdf with 364 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping Stategic Systems W2.pdf because it matches 0 rows\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing VMWARE W2.pdf with 505 tokens\n",
      "printing answers here 1         pdf_file  Wages,_tips_and_other_compensation  \\\n",
      "1  VMWARE W2.pdf                           202676.58   \n",
      "\n",
      "   Federal_Income_tax_withheld  Social_Security_wages  \\\n",
      "1                     41531.84               132900.0   \n",
      "\n",
      "   Social_security_tax_withheld  \n",
      "1                        8239.8  \n",
      "\n",
      "\n",
      " printing answers here 2\n",
      "\n",
      " pdf_file                              VMWARE W2.pdf\n",
      "Wages,_tips_and_other_compensation        202676.58\n",
      "Federal_Income_tax_withheld                41531.84\n",
      "Social_Security_wages                      132900.0\n",
      "Social_security_tax_withheld                 8239.8\n",
      "Name: 1, dtype: object\n",
      "type of answers <class 'pandas.core.series.Series'>\n",
      "\n",
      "target: Wages,_tips_and_other_compensation\n",
      "answer: 202676.58\n",
      "best_match array: [1.0, 1.0, 0.69]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['202676.58']\n",
      "Target Occurs at Indices: [92, 191, 193, 195]\n",
      "\n",
      "target: Federal_Income_tax_withheld\n",
      "answer: 41531.84\n",
      "best_match array: [1.0, 0.94, 0.64]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['41531.84']\n",
      "Target Occurs at Indices: [93, 192, 194, 196]\n",
      "\n",
      "target: Social_Security_wages\n",
      "answer: 132900.0\n",
      "best_match array: [0.86, 0.86, 0.86]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['132900']\n",
      "Target Occurs at Indices: [108, 209, 211, 213]\n",
      "\n",
      "target: Social_security_tax_withheld\n",
      "answer: 8239.8\n",
      "best_match array: [1.0, 0.92, 0.67]\n",
      "Best choice for number of tokens: 1\n",
      "Best Match Token Sequence: ['8239.8']\n",
      "Target Occurs at Indices: [109, 210, 212, 214]\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing W2 Wage _ Tax Statement  1.pdf with 197 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping W2 Wage _ Tax Statement  1.pdf because it matches 0 rows\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "Processing XPerttech W2.pdf with 670 tokens\n",
      "printing answers here 1 Empty DataFrame\n",
      "Columns: [pdf_file, Wages,_tips_and_other_compensation, Federal_Income_tax_withheld, Social_Security_wages, Social_security_tax_withheld]\n",
      "Index: []\n",
      "Skipping XPerttech W2.pdf because it matches 0 rows\n"
     ]
    }
   ],
   "source": [
    "# --- Main ---\n",
    "# Accumulate all rows with the same slug\n",
    "# active_rows = []\n",
    "# active_slug = None\n",
    "# input_docs = 0\n",
    "# max_n = 5\n",
    "#    for row in incsv:\n",
    "#     if row[\"slug\"] != active_slug:\n",
    "#         if active_slug:\n",
    "#             process_doc(active_slug, active_rows, max_n)\n",
    "#             input_docs += 1\n",
    "#         active_slug = row[\"slug\"]\n",
    "#         active_rows = [row]\n",
    "#     else:\n",
    "#         active_rows.append(row)\n",
    "\n",
    "# print(f\"Input documents {input_docs}\")\n",
    "# print(f\"Output documents {output_docs}\")\n",
    "\n",
    "\n",
    "# --- Main ---\n",
    "# Accumulate all rows with the same slug\n",
    "active_rows = []\n",
    "# active_slug = None\n",
    "input_docs = 0\n",
    "max_n = 3\n",
    "# for row in incsv:\n",
    "#     if row[\"slug\"] != active_slug:\n",
    "#         if active_slug:\n",
    "#             process_doc(active_slug, active_rows)\n",
    "#             input_docs += 1\n",
    "#         active_slug = row[\"slug\"]\n",
    "#         active_rows = [row]\n",
    "#     else:\n",
    "#         active_rows.append(row)\n",
    "n = 0\n",
    "for slug, group in incsv.groupby(\"slug\"):\n",
    "    process_doc(slug, group, max_n)\n",
    "    n += 1\n",
    "    if n > 200:\n",
    "        break\n",
    "# print(f\"Input documents {input_docs}\")\n",
    "# print(f\"Output documents {output_docs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a08cfce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
