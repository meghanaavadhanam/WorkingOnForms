{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58f311d",
   "metadata": {},
   "source": [
    "# tokenize pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07460194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version outputs a CSV in normal form:\n",
    "# slug, page, x, y, token\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2754097",
   "metadata": {},
   "outputs": [],
   "source": [
    "nopened = 0\n",
    "nparsed = 0\n",
    "nopenerror = 0\n",
    "nparseerror = 0\n",
    "\n",
    "def print_stats():\n",
    "    global nopened, nparsed, nopenerror, nparseerror\n",
    "    print('-----')\n",
    "    print(f'Found {nopened} files, could not open {nopenerror}')\n",
    "    print(f'Parsed {nparsed}, could not parse {nparseerror}')\n",
    "    print('-----')\n",
    "\n",
    "\n",
    "d = pd.read_csv('C:/Users/HP/Documents/work/DeepForm/deepform-master/files.csv')\n",
    "\n",
    "f = open('C:/Users/HP/Documents/work/DeepForm/deepform-master/my-tokens.csv', mode='w')\n",
    "csv = csv.writer(f)\n",
    "csv.writerow(['slug','x0','y0','x1','y1','token'])\n",
    "\n",
    "i=0\n",
    "\n",
    "for index, row in d.iterrows():\n",
    "#for i in range(3) :\n",
    "    \n",
    "    \n",
    "    slug = row['pdf files']\n",
    "    #slug = d.loc[i, \"dc_slug\"]\n",
    "    fname = 'C:/Users/HP/Documents/work/DeepForm/deepform-master/pdfs/' + slug\n",
    "    print('Extracting ' +  fname)\n",
    "\n",
    "    try:\n",
    "        pdf = pdfplumber.open(fname)\n",
    "        nopened += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        nopenerror += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        for p in range(len(pdf.pages)):\n",
    "            for w in pdf.pages[p].extract_words():\n",
    "                if '\\0' not in w['text']:  # some tokens have nulls in them, which are not valid in a csv\n",
    "                    csv.writerow([slug, \n",
    "                                p, \n",
    "                                float(w['x0']), \n",
    "                                float(w['top']), \n",
    "                                float(w['x1']), \n",
    "                                float(w['bottom']), \n",
    "                                w['text']])\n",
    "        nparsed += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        nparseerror +=1 \n",
    "\n",
    "    #if (index % 100) == 0:\n",
    "       # print_stats()\n",
    "\n",
    "#i = i+1\n",
    "\n",
    "print('-----')\n",
    "print(\"Done!\")\n",
    "print(f'{len(d)} rows total')\n",
    "print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302eb72c",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01656c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extraction by deep learning, using a fully connected architecture over token windows.\n",
    "# Engineered to extract total amounts, using a few custom features.\n",
    "# Achieves up to 90% accuracy.\n",
    "#\n",
    "# jstray 2019-6-12\n",
    "\n",
    "import keras as K\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Lambda, concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.backend import expand_dims, squeeze\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import pdfplumber\n",
    "import os\n",
    "import pickle\n",
    "from decimal import Decimal\n",
    "\n",
    "#import wandb\n",
    "#from wandb.keras import WandbCallback\n",
    "\n",
    "# uration\n",
    "#run = init(project=\"jonathan_summer_1\", entity=\"deepform\", name=\"testing\")\n",
    "\n",
    "# = run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a50912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# address some inteeface discrepancies when using tensorflow.keras\n",
    "if \"slice\" not in K.__dict__ and K.backend == \"tensorflow\":\n",
    "    # this is a good indicator that we are using tensorflow.keras\n",
    "\n",
    "    try:\n",
    "        # at first try to monkey patch what we need, will only work if keras-team keras is installed\n",
    "        from keras import backend as KKK\n",
    "\n",
    "        try:\n",
    "            K.__dict__.update(\n",
    "                is_tensor=KKK.is_tensor,\n",
    "                slice=KKK.slice,\n",
    "            )\n",
    "        finally:\n",
    "            del KKK\n",
    "    except ImportError:\n",
    "        # if that doesn't work we do a dirty copy of the code required\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.python.framework import ops as tf_ops\n",
    "\n",
    "\n",
    "        def is_tensor(x):\n",
    "            return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)\n",
    "\n",
    "\n",
    "        def slice(x, start, size):\n",
    "            x_shape = K.int_shape(x)\n",
    "            if (x_shape is not None) and (x_shape[0] is not None):\n",
    "                len_start = K.int_shape(start)[0] if is_tensor(start) else len(start)\n",
    "                len_size = K.int_shape(size)[0] if is_tensor(size) else len(size)\n",
    "                if not (len(K.int_shape(x)) == len_start == len_size):\n",
    "                    raise ValueError('The dimension and the size of indices should match.')\n",
    "            return tf.slice(x, start, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db599198",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_docs = 10 # how many docs to load, at most\n",
    "window_len = 30 # size of token sequences to train on (and network size!)\n",
    "vocab_size = 500\n",
    "token_dims = 6 # number of features per token, including token hash\n",
    "positive_fraction = 0.5\n",
    "target_thresh = 0.8 # target match scores larger than this will becomes positive labels\n",
    "epochs = 10\n",
    "batch_size=1000\n",
    "steps_per_epoch = 10\n",
    "doc_acc_sample_size = 5 # how many documents to check extraction on after each epoch\n",
    "penalize_missed = 5 # how much more a missed 1 counts than a missed 0 in output\n",
    "val_split = 0.2\n",
    "len_train = 80\n",
    "\n",
    "source_data = 'C:/Users/HP/Documents/work/DeepForm/deepform-master/mytrain.csv'\n",
    "pickle_destination = 'C:/Users/HP/Documents/work/DeepForm/deepform-master/source/save.p'\n",
    "\n",
    "# ---- Load data and generate features ----\n",
    "\n",
    "# Generator that reads raw training data\n",
    "# For each document, yields an array of dictionaries, each of which is a token\n",
    "def input_docs(max_docs=None):\n",
    "    incsv = csv.DictReader(open(source_data, mode='r'))\n",
    "\n",
    "    # Reconstruct documents by concatenating all rows with the same slug\n",
    "    active_slug = None\n",
    "    doc_rows = [] \n",
    "    num_docs = 0\n",
    "\n",
    "    for row in incsv:\t\n",
    "        # throw out tokens that are too short, they won't help us\n",
    "        token = row['token']\n",
    "        if len(token) < 3:\n",
    "            continue \n",
    "\n",
    "        if row['slug'] != active_slug:\n",
    "            if active_slug:\n",
    "                yield doc_rows\n",
    "                num_docs += 1\n",
    "                if max_docs and num_docs >= max_docs:\n",
    "                    return\n",
    "            doc_rows = [row]\n",
    "            active_slug = row['slug']\n",
    "        else:\n",
    "            doc_rows.append(row)\n",
    "\n",
    "    yield doc_rows\n",
    "\n",
    "\n",
    "def is_required_amount(s):\n",
    "    return re.search(r'\\$?\\d[\\d,]+(\\.\\d\\d)?',s) != None\n",
    "\n",
    "def token_features(row, vocab_size):\n",
    "    tokstr = row['token'].upper()\n",
    "    return [ hash(tokstr) % vocab_size,\n",
    "                     #float(row['page']), \n",
    "                     float(row['x0']),\n",
    "                     float(row['y0']), \n",
    "                     float(len(tokstr)),\n",
    "                     float(np.mean([c.isdigit() for c in tokstr])),\n",
    "                     float(is_required_amount(tokstr)) ]\n",
    "\n",
    "# Load raw training data, create our per-token features and binary labels\n",
    "def load_training_data_nocache():\n",
    "    slugs = []\n",
    "    token_text = []\n",
    "    features = []\n",
    "    label1 = []\n",
    "    for doc_tokens in input_docs(max_docs=read_docs):\n",
    "        if len(doc_tokens) < window_len:\n",
    "            continue # TODO pad shorter docs\n",
    "\n",
    "        # Not training data, but used for evaluating results later\n",
    "        slugs.append(doc_tokens[0]['slug']) # unique document ID, also PDF filename\n",
    "        token_text.append([row['token'] for row in doc_tokens])\n",
    "\n",
    "        features.append([token_features(row, vocab_size) for row in doc_tokens])\n",
    "\n",
    "        # threshold fuzzy matching score with our target field, to get binary labels \n",
    "        label1.append([(0 if float(row['Wages,_tips_and_other_compensation']) < target_thresh else 1) for row in doc_tokens])\n",
    "        \n",
    "    print(\"Length of slugs in load_training_data_nocache = \", len(slugs))\n",
    "    return slugs, token_text, features, label1\n",
    "\n",
    "# Because generating the list of features is so expensive, we cache it on disk\n",
    "\n",
    "def load_training_data():\n",
    "    if os.path.isfile(pickle_destination):\n",
    "        print('Loading training data from cache...')\n",
    "        #slugs, token_text, features = pickle.load(open(pickle_destination, 'rb'))\n",
    "        slugs, token_text, features, label1 = pickle.load(open(pickle_destination, 'rb'))\n",
    "    else:\n",
    "        print('Loading training data...')\n",
    "        #slugs, token_text, features = load_training_data_nocache()\n",
    "        slugs, token_text, features, label1 = load_training_data_nocache()\n",
    "        \n",
    "        print('Saving training data to cache...')\n",
    "        #pickle.dump((slugs, token_text, features), open(pickle_destination, 'wb'))\n",
    "        pickle.dump((slugs, token_text, features, label1), open(pickle_destination, 'wb'))\n",
    "\n",
    "    # Trim the training data so we can sweep across various training data sizes\n",
    "    print(\"Length of slugs in load_training_data before modification = \", len(slugs))\n",
    "    slugs = slugs[:len_train]\n",
    "    print(\"Length of slugs in load_training_data after modification = \", len(slugs))\n",
    "    token_text = token_text[:len_train]\n",
    "    features = features[:len_train]\n",
    "    label1 = label1[:len_train]\n",
    "\n",
    "    return slugs, token_text, features, label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5367cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Resample features,labels as windows ----\n",
    "\n",
    "# returns a window of tokens, labels at a random position in a random document\n",
    "def one_window_unbalanced(features, labels, window_len):\n",
    "    #def one_window_unbalanced(features, window_len, ):\n",
    "    '''if(len(features)<2):\n",
    "        doc_idx = 0\n",
    "        return None, None\n",
    "    else:'''    \n",
    "    doc_idx = random.randint(0,len(features)-1)\n",
    "    doc_len = len(features[doc_idx])\n",
    "    tok_idx = random.randint(0, doc_len-window_len)\n",
    "    return features[doc_idx][tok_idx : tok_idx+window_len], label1[doc_idx][tok_idx : tok_idx+window_len]\n",
    "\n",
    "# control the fraction of windows that include a positive label. not efficient.\n",
    "def one_window(features, label1, window_len, positive_fraction):\n",
    "    f,l = one_window_unbalanced(features, label1, window_len)   \n",
    "    if random.random() > positive_fraction: # mostly positive examples\n",
    "        while not 1 in l:\n",
    "            if(len(features)>1):\n",
    "                f,l = one_window_unbalanced(features, label1, window_len)\n",
    "            else:\n",
    "                continue\n",
    "    return f,l\n",
    "\n",
    "\n",
    "def windowed_generator(features, labels):\n",
    "    #def windowed_generator(features):    \n",
    "    # Create empty arrays to contain batch of features and labels#\n",
    "    \n",
    "    batch_features = np.zeros((batch_size, window_len, token_dims))\n",
    "    batch_labels = np.zeros((batch_size, window_len))\n",
    "\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            features1,labels1 = one_window(features, label1, window_len, positive_fraction)\n",
    "            #features1 = one_window_unbalanced(features, window_len)\n",
    "            if len(features1) == 6:\n",
    "                batch_features[i,:,:] = features1\n",
    "            if(len(labels1) == 30):    \n",
    "                batch_labels[i,:] = labels1\n",
    "                \n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab475ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from cache...\n",
      "Length of slugs in load_training_data before modification =  10\n",
      "Length of slugs in load_training_data after modification =  10\n",
      "Loaded 10\n",
      "Max document size 1968\n",
      "Average document size 932.2\n",
      "Training on 8, validating on 2\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 30, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 30)           0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 30, 32)       16000       lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 30, 5)        0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 30, 37)       0           embedding_7[0][0]                \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 1110)         0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 900)          999900      flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 900)          0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 180)          162180      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 180)          0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 30)           5430        dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,183,510\n",
      "Trainable params: 1,183,510\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 83ms/step - loss: 1.0661 - acc: 0.0244\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 14.459785401821136, correct \"96861.89\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 14.459785401821136, correct \"96861.89\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 14.459785401821136, correct \"96861.89\"\n",
      "Qual W2FORM.pdf: guessed \"compensation\" with score 14.641957104206085, correct \"108055.68\"\n",
      "VMWARE W2.pdf: guessed \"12d\" with score 14.808209016919136, correct \"202676.58\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "Sonus Software W2.pdf: guessed \"Stateincometax\" with score 14.41219738125801, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Stateincometax\" with score 14.41219738125801, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"compensation\" with score 14.64195704460144, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"compensation\" with score 14.64195704460144, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Stateincometax\" with score 14.41219738125801, correct \"2019\"\n",
      "This epoch doc_val_acc: 0.0\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.5954 - acc: 0.0300\n",
      "Intel W2.pdf: guessed \"MS-301\" with score 12.653618708252907, correct \"106468.39\"\n",
      "Qual W2FORM.pdf: guessed \"compensation\" with score 12.818434551358223, correct \"108055.68\"\n",
      "Qual W2FORM.pdf: guessed \"compensation\" with score 12.818434551358223, correct \"108055.68\"\n",
      "OpenLogix W2.pdf: guessed \"19Localincometax\" with score 12.723686754703522, correct \"NoticetoEmployee\"\n",
      "Intel W2.pdf: guessed \"MS-301\" with score 12.653618708252907, correct \"106468.39\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 12.721018768846989, correct \"96861.89\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 12.646824762225151, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 12.646824762225151, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"compensation\" with score 12.818434610962868, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"compensation\" with score 12.818434610962868, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 12.646824762225151, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"compensation\" with score 12.818434610962868, correct \"131558.7\"\n",
      "This epoch doc_val_acc: 0.0\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.5146 - acc: 0.0229\n",
      "Qual W2FORM.pdf: guessed \"45-3157787\" with score 13.557460904121399, correct \"108055.68\"\n",
      "Oath W2.pdf: guessed \"tax\" with score 13.612238138914108, correct \"150207.24\"\n",
      "W2 Wage _ Tax Statement  1.pdf: guessed \"Tensor\" with score 12.71777480840683, correct \"Employeeï¿½s\"\n",
      "Intel W2.pdf: guessed \"MS-301\" with score 13.532990843057632, correct \"106468.39\"\n",
      "Oath W2.pdf: guessed \"tax\" with score 13.612238138914108, correct \"150207.24\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 13.58449175953865, correct \"96861.89\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 13.578297793865204, correct \"135405.59\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 13.616632997989655, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 13.551035195589066, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 13.616632997989655, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 13.616632997989655, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 13.551035195589066, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 13.551035195589066, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 13.551035195589066, correct \"2019\"\n",
      "This epoch doc_val_acc: 0.0\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.4876 - acc: 0.0254\n",
      "Oath W2.pdf: guessed \"tax\" with score 14.114146173000336, correct \"150207.24\"\n",
      "W2 Wage _ Tax Statement  1.pdf: guessed \"Tensor\" with score 13.125771224498749, correct \"Employeeï¿½s\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 14.11252972483635, correct \"96861.89\"\n",
      "Qual W2FORM.pdf: guessed \"434.4\" with score 14.040062695741653, correct \"108055.68\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 14.038501650094986, correct \"135405.59\"\n",
      "Qual W2FORM.pdf: guessed \"434.4\" with score 14.040062695741653, correct \"108055.68\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 14.038501650094986, correct \"135405.59\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 14.11252972483635, correct \"96861.89\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 14.070905566215515, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 14.070905566215515, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 14.070905566215515, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.095292538404465, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 14.070905566215515, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 14.070905566215515, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"RX/YM9\" with score 14.070905566215515, correct \"2019\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.095292538404465, correct \"131558.7\"\n",
      "This epoch doc_val_acc: 0.0\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.4872 - acc: 0.0249\n",
      "Intel W2.pdf: guessed \"1756.96\" with score 14.345356047153473, correct \"106468.39\"\n",
      "VMWARE W2.pdf: guessed \"AUSTIN\" with score 14.437369972467422, correct \"202676.58\"\n",
      "Intel W2.pdf: guessed \"1756.96\" with score 14.345356047153473, correct \"106468.39\"\n",
      "Intel W2.pdf: guessed \"1756.96\" with score 14.345356047153473, correct \"106468.39\"\n",
      "OpenLogix W2.pdf: guessed \"1Wages,tips,othercompe7ns4at1io4n0.00\" with score 14.419835925102234, correct \"NoticetoEmployee\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 14.46688911318779, correct \"135405.59\"\n",
      "Oath W2.pdf: guessed \"tax\" with score 14.49444654583931, correct \"150207.24\"\n",
      "OpenLogix W2.pdf: guessed \"1Wages,tips,othercompe7ns4at1io4n0.00\" with score 14.419835925102234, correct \"NoticetoEmployee\"\n",
      "Oath W2.pdf: guessed \"tax\" with score 14.49444654583931, correct \"150207.24\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.485690534114838, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.484250634908676, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.484250634908676, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.485690534114838, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.485690534114838, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.484250634908676, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.484250634908676, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.484250634908676, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.484250634908676, correct \"2019\"\n",
      "This epoch doc_val_acc: 0.0\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 86ms/step - loss: 0.4752 - acc: 0.0204\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 14.82430624961853, correct \"96861.89\"\n",
      "OpenLogix W2.pdf: guessed \"1Wages,tips,othercompe7ns4at1io4n0.00\" with score 14.752917498350143, correct \"NoticetoEmployee\"\n",
      "W2 Wage _ Tax Statement  1.pdf: guessed \"Tensor\" with score 13.494136720895767, correct \"Employeeï¿½s\"\n",
      "Oath W2.pdf: guessed \"tax\" with score 14.810901761054993, correct \"150207.24\"\n",
      "Qual W2FORM.pdf: guessed \"3298.1\" with score 14.79633155465126, correct \"108055.68\"\n",
      "ISN W2.pdf: guessed \"353\" with score 14.832291960716248, correct \"135405.59\"\n",
      "VMWARE W2.pdf: guessed \"AUSTIN\" with score 14.801502227783203, correct \"202676.58\"\n",
      "W2 Wage _ Tax Statement  1.pdf: guessed \"Tensor\" with score 13.494136720895767, correct \"Employeeï¿½s\"\n",
      "OpenLogix W2.pdf: guessed \"1Wages,tips,othercompe7ns4at1io4n0.00\" with score 14.752917498350143, correct \"NoticetoEmployee\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 14.82430624961853, correct \"96861.89\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.831429898738861, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.831429898738861, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.825619608163834, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.831429898738861, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.831429898738861, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.825619608163834, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.825619608163834, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 14.831429898738861, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.825619608163834, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 14.825619608163834, correct \"131558.7\"\n",
      "This epoch doc_val_acc: 0.0\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.4717 - acc: 0.0245\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 15.668470561504364, correct \"96861.89\"\n",
      "Intel W2.pdf: guessed \"Mission\" with score 15.541518568992615, correct \"106468.39\"\n",
      "W2 Wage _ Tax Statement  1.pdf: guessed \"Control\" with score 14.256823778152466, correct \"Employeeï¿½s\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 15.668470561504364, correct \"96861.89\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.700362771749496, correct \"135405.59\"\n",
      "OpenLogix W2.pdf: guessed \"1Wages,tips,othercompe7ns4at1io4n0.00\" with score 15.631818413734436, correct \"NoticetoEmployee\"\n",
      "Qual W2FORM.pdf: guessed \"618-63-4182\" with score 15.652685075998306, correct \"108055.68\"\n",
      "OpenLogix W2.pdf: guessed \"1Wages,tips,othercompe7ns4at1io4n0.00\" with score 15.631818413734436, correct \"NoticetoEmployee\"\n",
      "Qual W2FORM.pdf: guessed \"618-63-4182\" with score 15.652685075998306, correct \"108055.68\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 15.668470561504364, correct \"96861.89\"\n",
      "Oath W2.pdf: guessed \"tax\" with score 15.641626685857773, correct \"150207.24\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.662188827991486, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.662188827991486, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.709472358226776, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.709472358226776, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.662188827991486, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.662188827991486, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.662188827991486, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.662188827991486, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.709472358226776, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.662188827991486, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.709472358226776, correct \"2019\"\n",
      "This epoch doc_val_acc: 0.0\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.4671 - acc: 0.0237\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.61184024810791, correct \"135405.59\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 15.551332771778107, correct \"96861.89\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.61184024810791, correct \"135405.59\"\n",
      "VMWARE W2.pdf: guessed \"AUSTIN\" with score 15.57850033044815, correct \"202676.58\"\n",
      "W2 Wage _ Tax Statement  1.pdf: guessed \"Control\" with score 14.12779587507248, correct \"Employeeï¿½s\"\n",
      "VMWARE W2.pdf: guessed \"AUSTIN\" with score 15.57850033044815, correct \"202676.58\"\n",
      "OpenLogix W2.pdf: guessed \"66.65\" with score 15.52989262342453, correct \"NoticetoEmployee\"\n",
      "W2 Wage _ Tax Statement  1.pdf: guessed \"Control\" with score 14.12779587507248, correct \"Employeeï¿½s\"\n",
      "VMWARE W2.pdf: guessed \"AUSTIN\" with score 15.57850033044815, correct \"202676.58\"\n",
      "Qual W2FORM.pdf: guessed \"618-63-4182\" with score 15.58311414718628, correct \"108055.68\"\n",
      "Intel W2.pdf: guessed \"Mission\" with score 15.48497885465622, correct \"106468.39\"\n",
      "Qual W2FORM.pdf: guessed \"618-63-4182\" with score 15.58311414718628, correct \"108055.68\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.640243798494339, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.556104272603989, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.556104272603989, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.556104272603989, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.556104272603989, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.640243798494339, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.640243798494339, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.640243798494339, correct \"2019\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.640243798494339, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.640243798494339, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.640243798494339, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.556104272603989, correct \"131558.7\"\n",
      "This epoch doc_val_acc: 0.0\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.4657 - acc: 0.0259\n",
      "Intel W2.pdf: guessed \"Mission\" with score 15.321691662073135, correct \"106468.39\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.48041957616806, correct \"135405.59\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 15.406005561351776, correct \"96861.89\"\n",
      "Intel W2.pdf: guessed \"Mission\" with score 15.321691662073135, correct \"106468.39\"\n",
      "OpenLogix W2.pdf: guessed \"66.65\" with score 15.379662841558456, correct \"NoticetoEmployee\"\n",
      "Qual W2FORM.pdf: guessed \"618-63-4182\" with score 15.436933130025864, correct \"108055.68\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.48041957616806, correct \"135405.59\"\n",
      "Stategic Systems W2.pdf: guessed \"1Wages,tips,othercompe9ns6at8io6n1.89\" with score 15.406005561351776, correct \"96861.89\"\n",
      "Oath W2.pdf: guessed \"tax\" with score 15.353170961141586, correct \"150207.24\"\n",
      "OpenLogix W2.pdf: guessed \"66.65\" with score 15.379662841558456, correct \"NoticetoEmployee\"\n",
      "OpenLogix W2.pdf: guessed \"66.65\" with score 15.379662841558456, correct \"NoticetoEmployee\"\n",
      "Oath W2.pdf: guessed \"tax\" with score 15.353170961141586, correct \"150207.24\"\n",
      "VMWARE W2.pdf: guessed \"AUSTIN\" with score 15.44309687614441, correct \"202676.58\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.471813827753067, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"FRISCO\" with score 15.35793188214302, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.471813827753067, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.471813827753067, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.471813827753067, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"FRISCO\" with score 15.35793188214302, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"FRISCO\" with score 15.35793188214302, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.471813827753067, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.471813827753067, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"FRISCO\" with score 15.35793188214302, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"FRISCO\" with score 15.35793188214302, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.471813827753067, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"FRISCO\" with score 15.35793188214302, correct \"131558.7\"\n",
      "This epoch doc_val_acc: 0.0\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.4656 - acc: 0.0240\n",
      "VMWARE W2.pdf: guessed \"AUSTIN\" with score 15.148141860961914, correct \"202676.58\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.230126678943634, correct \"135405.59\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.230126678943634, correct \"135405.59\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.230126678943634, correct \"135405.59\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.230126678943634, correct \"135405.59\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.230126678943634, correct \"135405.59\"\n",
      "Intel W2.pdf: guessed \"1756.96\" with score 15.08471605181694, correct \"106468.39\"\n",
      "Intel W2.pdf: guessed \"1756.96\" with score 15.08471605181694, correct \"106468.39\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.230126678943634, correct \"135405.59\"\n",
      "W2 Wage _ Tax Statement  1.pdf: guessed \"Control\" with score 13.790265023708344, correct \"Employeeï¿½s\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.230126678943634, correct \"135405.59\"\n",
      "OpenLogix W2.pdf: guessed \"66.65\" with score 15.142877697944641, correct \"NoticetoEmployee\"\n",
      "Intel W2.pdf: guessed \"1756.96\" with score 15.08471605181694, correct \"106468.39\"\n",
      "ISN W2.pdf: guessed \"Other\" with score 15.230126678943634, correct \"135405.59\"\n",
      "This epoch doc_train_acc: 0.0\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.180872678756714, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.180872678756714, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.131191700696945, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.131191700696945, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.131191700696945, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.180872678756714, correct \"2019\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.180872678756714, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.131191700696945, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.131191700696945, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.131191700696945, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.131191700696945, correct \"131558.7\"\n",
      "Sonus Software W2.pdf: guessed \"Employeeï¿½sSSAnumber\" with score 15.180872678756714, correct \"2019\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.131191700696945, correct \"131558.7\"\n",
      "CAPRUS W2.pdf: guessed \"HILLSBOROOR97124\" with score 15.131191700696945, correct \"131558.7\"\n",
      "This epoch doc_val_acc: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ddf3bf370>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Custom loss function is basically MSE but high penalty for missing a 1 label ---\n",
    "\n",
    "def missed_token_loss(one_penalty):\n",
    "   \n",
    "    def _missed_token_loss(y_true, y_pred):\n",
    "        expected_zero = tf.cast(tf.math.equal(y_true,0), tf.float32)\n",
    "        s = y_pred*expected_zero\n",
    "        zero_loss = K.backend.mean(K.backend.square(s))\n",
    "        expected_one = tf.cast(tf.math.equal(y_true,1), tf.float32)\n",
    "        t = one_penalty*(1-y_pred)*expected_one\n",
    "        one_loss = K.backend.mean(K.backend.square(t))\n",
    "        return zero_loss + one_loss\n",
    "\n",
    "    return _missed_token_loss # closes over one_penalty\n",
    "\n",
    "# --- Specify network ---\n",
    "\n",
    "def create_model():\n",
    "    indata = Input((window_len, token_dims))\n",
    "\n",
    "    # split into the hash and the rest of the token features, embed hash as one-hot, then merge\n",
    "    tok_hash = Lambda( lambda x: squeeze(tf.slice(x, (0,0,0), (-1,-1,1)),axis=2))(indata)\n",
    "    tok_features = Lambda( lambda x: tf.slice(x, (0,0,1), (-1,-1,-1)))(indata)\n",
    "    embed = Embedding(vocab_size, 32)(tok_hash)\n",
    "    merged = concatenate([embed, tok_features], axis=2)\n",
    "\n",
    "    f = Flatten()(merged)\n",
    "    d1 = Dense(window_len*token_dims*5, activation='sigmoid')(f)\n",
    "    d2 = Dropout(0.3)(d1)\n",
    "    d3 = Dense(window_len*token_dims, activation='sigmoid')(d2)\n",
    "    d4 = Dropout(0.3)(d3)\n",
    "    d5 = Dense(window_len, activation='elu')(d4)\n",
    "\n",
    "    model = Model(inputs=[indata], outputs=[d5])\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss=missed_token_loss(penalize_missed), \n",
    "        metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# --- Predict ---\n",
    "# Our network is windowed, so we have to aggregate windows to get a final score\n",
    "\n",
    "# Returns vector of token scores\n",
    "def predict_scores(model, features, window_len):\n",
    "    doc_len = len(features)\n",
    "    num_windows = doc_len-window_len\n",
    "\n",
    "    windowed_features = np.array([features[i:i+window_len] for i in range(num_windows)])\n",
    "    window_scores = model.predict(windowed_features)\n",
    "\n",
    "    scores = np.zeros(doc_len)\n",
    "    for i in range(num_windows):\n",
    "        scores[i:i+window_len] += window_scores[i] # would max work better than sum?\n",
    "    return scores\n",
    "\n",
    "# returns text, score of best answer\n",
    "def predict_answer(model, features, token_text, window_len):\n",
    "\tscores = predict_scores(model, features, window_len)\n",
    "\tbest_score_idx = np.argmax(scores)\n",
    "\tbest_score_text = token_text[best_score_idx]\n",
    "\treturn best_score_text, scores[best_score_idx]\n",
    "\n",
    "\n",
    "# returns text of correct answer,\n",
    "def correct_answer(features, label1, token_text):\n",
    "\tanswer_idx = np.argmax(label1)\n",
    "\tanswer_text = token_text[answer_idx]\n",
    "\treturn answer_text\n",
    "\n",
    "\n",
    "# Calculate accuracy of answer extraction over num_to_test docs, print diagnostics while we do so\n",
    "def compute_accuracy(model, window_len, slugs, token_text, features, label1, num_to_test):\n",
    "\tacc = 0.0\n",
    "\tfor i in range(num_to_test):\n",
    "\t\tdoc_idx = random.randint(0, len(slugs)-1)\n",
    "\t\tpredict_text, predict_score = predict_answer(model, features[doc_idx], token_text[doc_idx], window_len)\n",
    "\t\tanswer_text = correct_answer(features[doc_idx], label1[doc_idx], token_text[doc_idx])\n",
    "\t\tprint(f'{slugs[doc_idx]}: guessed \"{predict_text}\" with score {predict_score}, correct \"{answer_text}\"')\n",
    "\t\tif predict_text==answer_text:\n",
    "\t\t\tacc+=1\n",
    "\treturn acc/num_to_test\n",
    "\n",
    "\n",
    "# ---- Custom callback to log document-level accuracy ----\n",
    "\n",
    "class DocAccCallback(K.callbacks.Callback):\n",
    "\tdef __init__(self, window_len, slugs, token_text, features, label1, num_to_test, logname):\n",
    "\t\tself.window_len = window_len\n",
    "\t\tself.slugs = slugs\n",
    "\t\tself.token_text = token_text\n",
    "\t\tself.features = features\n",
    "\t\tself.label1 = label1\n",
    "\t\tself.num_to_test = num_to_test\n",
    "\t\tself.logname = logname\n",
    "\n",
    "\tdef on_epoch_end(self, epoch, logs):\n",
    "\t\tacc = compute_accuracy(self.model,\n",
    "\t\t\tself.window_len,\n",
    "\t\t\tself.slugs,\n",
    "\t\t\tself.token_text,\n",
    "\t\t\tself.features,\n",
    "\t\t\tself.label1,\n",
    "\t\t\tself.num_to_test+epoch)  # test more docs later in training, for more precise acc\n",
    "\t\tprint(f'This epoch {self.logname}: {acc}')\n",
    "\t\t#wandb.log({self.logname:acc})\n",
    "\n",
    "\n",
    "# --- MAIN ----\n",
    "\n",
    "#print('uration:')\n",
    "#print()\n",
    "maxarray = []\n",
    "summation = 0\n",
    "max_length = 0\n",
    "slugs, token_text, features, label1 = load_training_data()\n",
    "print(f'Loaded {len(features)}')\n",
    "#max_length = max([len(x) for x in label1])\n",
    "\n",
    "for x in label1:\n",
    "    maxarray.append(len(x))\n",
    "    summation = summation + len(x)\n",
    "    \n",
    "if (maxarray):    \n",
    "    max_length = max(maxarray)\n",
    "    print(f'Max document size {max_length}')\n",
    "    \n",
    "    avg_length = summation/len(label1)\n",
    "    print(f'Average document size {avg_length}')\n",
    "\n",
    "else:\n",
    "    print(\"labels don't exist here\")\n",
    "    \n",
    "# split into train and test\n",
    "slugs_train = []\n",
    "token_text_train = []\n",
    "features_train = []\n",
    "labels_train = []\n",
    "slugs_val = []\n",
    "token_text_val = []\n",
    "features_val = []\n",
    "labels_val = []\n",
    "for i in range(len(features)):\n",
    "\tif random.random() < val_split:\n",
    "\t\tslugs_val.append(slugs[i])\n",
    "\t\ttoken_text_val.append(token_text[i])\n",
    "\t\tfeatures_val.append(features[i])\n",
    "\t\tlabels_val.append(label1[i])\n",
    "\telse:\n",
    "\t\tslugs_train.append(slugs[i])\n",
    "\t\ttoken_text_train.append(token_text[i])\t\t\n",
    "\t\tfeatures_train.append(features[i])\n",
    "\t\tlabels_train.append(label1[i])\n",
    "\n",
    "print(f'Training on {len(features_train)}, validating on {len(features_val)}')\n",
    "\n",
    "model = create_model()\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    windowed_generator(features_train, labels_train),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[ \n",
    "        #WandbCallback(),\n",
    "        DocAccCallback(\twindow_len, \n",
    "                                        slugs_train, \n",
    "                                        token_text_train, \n",
    "                                        features_train, \n",
    "                                        labels_train, \n",
    "                                        doc_acc_sample_size,\n",
    "                                        'doc_train_acc'),\n",
    "        DocAccCallback(\twindow_len, \n",
    "                                        slugs_val, \n",
    "                                        token_text_val, \n",
    "                                        features_val, \n",
    "                                        labels_val, \n",
    "                                        doc_acc_sample_size,\n",
    "                                        'doc_val_acc')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec88f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
