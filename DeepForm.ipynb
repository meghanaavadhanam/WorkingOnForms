{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0d0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5aad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/HP/Documents/work/DeepForm/deepform-master/source/ftf-all-filings.tsv\", delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe5b340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filing_type</th>\n",
       "      <th>contract_number</th>\n",
       "      <th>url</th>\n",
       "      <th>committee</th>\n",
       "      <th>agency</th>\n",
       "      <th>callsign</th>\n",
       "      <th>dc_slug</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>gross_amount</th>\n",
       "      <th>market_id</th>\n",
       "      <th>upload_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23969</td>\n",
       "      <td>Federal</td>\n",
       "      <td>314271</td>\n",
       "      <td>/collect/files/59438/Political File/2012/Feder...</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "      <td>STRATEGIC MEDIA SERVICES</td>\n",
       "      <td>WCPO-TV</td>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>21100.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2012-10-10 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2333</td>\n",
       "      <td>Non-Candidate Issue Ads</td>\n",
       "      <td>9792042</td>\n",
       "      <td>/collect/files/11289/Political File/2012/Non-C...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>MENTZER MEDIA SERVICES</td>\n",
       "      <td>WKRC-TV</td>\n",
       "      <td>416491-collect-files-11289-political-file-2012...</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>6250.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2012-08-14 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31990</td>\n",
       "      <td>Federal</td>\n",
       "      <td>336298</td>\n",
       "      <td>/collect/files/73910/Political File/2012/Feder...</td>\n",
       "      <td>POL/R TERRY/D/PRES/US</td>\n",
       "      <td>KATHLEEN OFFERMAN</td>\n",
       "      <td>WPXI</td>\n",
       "      <td>470297-101612-terry-contract-2-13504017232906-...</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2012-10-16 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33211</td>\n",
       "      <td>Federal</td>\n",
       "      <td>116252</td>\n",
       "      <td>/collect/files/73123/Political File/2012/Feder...</td>\n",
       "      <td>COMMITTEE TO ELECT SHANELLE JACKSON</td>\n",
       "      <td>SHANELLE JACKSON FOR CONGRESS</td>\n",
       "      <td>WJBK</td>\n",
       "      <td>473630-116252-0-13442821773323-_-pdf</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2012-08-06 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6213</td>\n",
       "      <td>Non-Candidate Issue Ads</td>\n",
       "      <td>48982</td>\n",
       "      <td>/collect/files/72313/Political File/2012/Non-C...</td>\n",
       "      <td>PRIORITIES USA ACTION</td>\n",
       "      <td>MUNDY KATOWITZ MEDIA</td>\n",
       "      <td>WHP-TV</td>\n",
       "      <td>420426-collect-files-72313-political-file-2012...</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>9335.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2012-08-13 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id              filing_type contract_number  \\\n",
       "0  23969                  Federal          314271   \n",
       "1   2333  Non-Candidate Issue Ads         9792042   \n",
       "2  31990                  Federal          336298   \n",
       "3  33211                  Federal          116252   \n",
       "4   6213  Non-Candidate Issue Ads           48982   \n",
       "\n",
       "                                                 url  \\\n",
       "0  /collect/files/59438/Political File/2012/Feder...   \n",
       "1  /collect/files/11289/Political File/2012/Non-C...   \n",
       "2  /collect/files/73910/Political File/2012/Feder...   \n",
       "3  /collect/files/73123/Political File/2012/Feder...   \n",
       "4  /collect/files/72313/Political File/2012/Non-C...   \n",
       "\n",
       "                             committee                         agency  \\\n",
       "0               NRSC-MANDEL/REPUBLICAN       STRATEGIC MEDIA SERVICES   \n",
       "1                      60+ ASSOCIATION         MENTZER MEDIA SERVICES   \n",
       "2                POL/R TERRY/D/PRES/US              KATHLEEN OFFERMAN   \n",
       "3  COMMITTEE TO ELECT SHANELLE JACKSON  SHANELLE JACKSON FOR CONGRESS   \n",
       "4                PRIORITIES USA ACTION           MUNDY KATOWITZ MEDIA   \n",
       "\n",
       "  callsign                                            dc_slug  \\\n",
       "0  WCPO-TV   459790-nrsc_mandel_rep_senate_1010_101412_314271   \n",
       "1  WKRC-TV  416491-collect-files-11289-political-file-2012...   \n",
       "2     WPXI  470297-101612-terry-contract-2-13504017232906-...   \n",
       "3     WJBK               473630-116252-0-13442821773323-_-pdf   \n",
       "4   WHP-TV  420426-collect-files-72313-political-file-2012...   \n",
       "\n",
       "                                       thumbnail_url  gross_amount  market_id  \\\n",
       "0  https://s3.amazonaws.com/s3.documentcloud.org/...       21100.0       35.0   \n",
       "1  https://s3.amazonaws.com/s3.documentcloud.org/...        6250.0       35.0   \n",
       "2  https://s3.amazonaws.com/s3.documentcloud.org/...          30.0       23.0   \n",
       "3  https://s3.amazonaws.com/s3.documentcloud.org/...        1170.0       11.0   \n",
       "4  https://s3.amazonaws.com/s3.documentcloud.org/...        9335.0       41.0   \n",
       "\n",
       "               upload_date  \n",
       "0  2012-10-10 00:00:00 UTC  \n",
       "1  2012-08-14 00:00:00 UTC  \n",
       "2  2012-10-16 00:00:00 UTC  \n",
       "3  2012-08-06 00:00:00 UTC  \n",
       "4  2012-08-13 00:00:00 UTC  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c019a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'470297-101612-terry-contract-2-13504017232906-_-pdf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dc_slug'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf028476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459790-nrsc_mandel_rep_senate_1010_101412_314271\n",
      "416491-collect-files-11289-political-file-2012-non\n",
      "470297-101612-terry-contract-2-13504017232906-_-pdf\n"
     ]
    }
   ],
   "source": [
    "#for index, row in data.iterrows(0:3):\n",
    " #   print(data['dc_slug'])\n",
    "    \n",
    "for i in range(3) :\n",
    "    slug = data.loc[i, \"dc_slug\"]\n",
    "    print(slug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fb1201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e7ec414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb.keras as wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19e8a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data extraction by deep learning, using a fully connected architecture over token windows.\n",
    "# Engineered to extract total amounts, using a few custom features.\n",
    "# Achieves up to 90% accuracy.\n",
    "#\n",
    "# jstray 2019-6-12\n",
    "\n",
    "import keras as K\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Lambda, concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.backend import expand_dims, squeeze\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import pdfplumber\n",
    "import os\n",
    "import pickle\n",
    "from decimal import Decimal\n",
    "\n",
    "#import wandb\n",
    "#from wandb.keras import WandbCallback\n",
    "\n",
    "# uration\n",
    "#run = init(project=\"jonathan_summer_1\", entity=\"deepform\", name=\"testing\")\n",
    "\n",
    "# = run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35d348ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-fd7352fd4cc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# address some inteeface discrepancies when using tensorflow.keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m\"slice\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tensorflow\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# this is a good indicator that we are using tensorflow.keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# address some inteeface discrepancies when using tensorflow.keras\n",
    "if \"slice\" not in K.__dict__ and K.backend() == \"tensorflow\":\n",
    "    # this is a good indicator that we are using tensorflow.keras\n",
    "\n",
    "    try:\n",
    "        # at first try to monkey patch what we need, will only work if keras-team keras is installed\n",
    "        from keras import backend as KKK\n",
    "\n",
    "        try:\n",
    "            K.__dict__.update(\n",
    "                is_tensor=KKK.is_tensor,\n",
    "                slice=KKK.slice,\n",
    "            )\n",
    "        finally:\n",
    "            del KKK\n",
    "    except ImportError:\n",
    "        # if that doesn't work we do a dirty copy of the code required\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.python.framework import ops as tf_ops\n",
    "\n",
    "\n",
    "        def is_tensor(x):\n",
    "            return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)\n",
    "\n",
    "\n",
    "        def slice(x, start, size):\n",
    "            x_shape = K.int_shape(x)\n",
    "            if (x_shape is not None) and (x_shape[0] is not None):\n",
    "                len_start = K.int_shape(start)[0] if is_tensor(start) else len(start)\n",
    "                len_size = K.int_shape(size)[0] if is_tensor(size) else len(size)\n",
    "                if not (len(K.int_shape(x)) == len_start == len_size):\n",
    "                    raise ValueError('The dimension and the size of indices should match.')\n",
    "            return tf.slice(x, start, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "581f1ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from cache...\n",
      "Length of slugs in load_training_data before modification =  100\n",
      "Length of slugs in load_training_data after modification =  80\n",
      "Loaded 80\n",
      "Max document size 9873\n",
      "Average document size 1692.5875\n",
      "Training on 61, validating on 19\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 30, 7)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 30)           0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 32)       16000       lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 30, 6)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 38)       0           embedding[0][0]                  \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1140)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1050)         1198050     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1050)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 210)          220710      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 210)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           6330        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,441,090\n",
      "Trainable params: 1,441,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function missed_token_loss.<locals>._missed_token_loss at 0x00000178B9AFA0D0> and will run it as-is.\n",
      "Cause: code mixing tabs and spaces for indentation is not allowed\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function missed_token_loss.<locals>._missed_token_loss at 0x00000178B9AFA0D0> and will run it as-is.\n",
      "Cause: code mixing tabs and spaces for indentation is not allowed\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10/10 [==============================] - 25s 919ms/step - loss: 1.0001 - acc: 0.0385\n",
      "468469-menendez-order-4-13500774152684-_-pdf: guessed \"$41,450.00\" with score 13.516670793294907, correct \"$41,450.00\"\n",
      "511281-336563-4-13524183201766-_-pdf: guessed \"$22,780.00\" with score 13.853281378746033, correct \"$26,800.00\"\n",
      "470486-kirkpatrick_1009-1015rev6-13503492049654-_-pdf: guessed \"KTVK\" with score 13.831149652600288, correct \"$20,030.00\"\n",
      "511316-obama-2051-final_341803-1-13524183386707-_-pdf: guessed \"$162,190.00\" with score 13.966634452342987, correct \"$162,190.00\"\n",
      "435451-collect-files-23079-political-file-2012-non: guessed \"$63,850.00\" with score 14.089594632387161, correct \"$63,850.00\"\n",
      "511293-341356-4-13524181194607-_-pdf: guessed \"1.50\" with score 13.645669847726822, correct \"$94,525.00\"\n",
      "511316-obama-2051-final_341803-1-13524183386707-_-pdf: guessed \"$162,190.00\" with score 13.966634452342987, correct \"$162,190.00\"\n",
      "511290-344206-2-13524181028832-_-pdf: guessed \"$9,750.00\" with score 13.880847737193108, correct \"$9,750.00\"\n",
      "511318-obama-2175-final_343497-1-13524183408511-_-pdf: guessed \"$30,000.00\" with score 13.790956228971481, correct \"$180,260.00\"\n",
      "511297-345394-0-13524180941700-_-pdf: guessed \"$20,000.00\" with score 13.561427533626556, correct \"$2,000.00\"\n",
      "511285-344110-0-13524181205225-_-pdf: guessed \"Rating\" with score 13.448047861456871, correct \"$27,675.00\"\n",
      "470522-american-action-network-est-3352-13503978063254: guessed \"$27,100.00\" with score 14.012003898620605, correct \"$27,100.00\"\n",
      "457315-romney-for-president-wo-10-6-order: guessed \"$30,500.00\" with score 14.089748442173004, correct \"$30,500.00\"\n",
      "511288-342852-2-13524183124047-_-pdf: guessed \"$1,800.00\" with score 13.751624673604965, correct \"$110,200.00\"\n",
      "420232-collect-files-39746-political-file-2012-non: guessed \"$6,950.00\" with score 13.877031311392784, correct \"$6,950.00\"\n",
      "469335-paton_1018-1024rev2-13503483811618-_-pdf: guessed \"0.00\" with score 13.846704423427582, correct \"$10,750.00\"\n",
      "470522-american-action-network-est-3352-13503978063254: guessed \"$27,100.00\" with score 14.012003898620605, correct \"$27,100.00\"\n",
      "511320-romney-387-final_337905-1-13524181105942-_-pdf: guessed \"--111--\" with score 13.86024522781372, correct \"$212,600.00\"\n",
      "433986-collect-files-68883-political-file-2012-non: guessed \"$18,000.00\" with score 14.148401886224747, correct \"$18,000.00\"\n",
      "433986-collect-files-68883-political-file-2012-non: guessed \"$18,000.00\" with score 14.148401886224747, correct \"$18,000.00\"\n",
      "470233-arpaio-10_16722619-13504209200222-_-pdf: guessed \"$50,925.00\" with score 14.090677663683891, correct \"$50,925.00\"\n",
      "436582-collect-files-23079-political-file-2012-non: guessed \"$193,200.00\" with score 13.746254175901413, correct \"$193,200.00\"\n",
      "511322-romney-505-final_342216-1-13524181139554-_-pdf: guessed \"$3,000.00\" with score 13.724924832582474, correct \"$235,610.00\"\n",
      "480022-67469-1-13509189034926-_-pdf: guessed \"$43,259.26\" with score 13.598463043570518, correct \"$11,680.00\"\n",
      "511319-rncromney-483-final_339838-1-13524180984389-_-pdf: guessed \"$1,620.00\" with score 13.824687898159027, correct \"$226,220.00\"\n",
      "This epoch doc_train_acc: 0.52\n",
      "419754-collect-files-65684-political-file-2012-federal: guessed \"$99,641.25\" with score 14.288009852170944, correct \"$117,225.00\"\n",
      "511282-339995-1-13524183255885-_-pdf: guessed \"$44,950.00\" with score 13.702718734741211, correct \"$44,950.00\"\n",
      "424758-collect-files-35576-political-file-2012-federal: guessed \"$25,680.00\" with score 14.090196907520294, correct \"$25,680.00\"\n",
      "511282-339995-1-13524183255885-_-pdf: guessed \"$44,950.00\" with score 13.702718734741211, correct \"$44,950.00\"\n",
      "431304-collect-files-35576-political-file-2012-federal: guessed \"$240.00\" with score 13.903667628765106, correct \"$85,740.00\"\n",
      "457316-romney-for-president-wo-10-6-rev-order: guessed \"$30,500.00\" with score 14.089748442173004, correct \"$30,500.00\"\n",
      "419754-collect-files-65684-political-file-2012-federal: guessed \"$99,641.25\" with score 14.288009852170944, correct \"$117,225.00\"\n",
      "511282-339995-1-13524183255885-_-pdf: guessed \"$44,950.00\" with score 13.702718734741211, correct \"$44,950.00\"\n",
      "511295-344107-1-13524180973818-_-pdf: guessed \"$22,000.00\" with score 14.019751787185669, correct \"$22,000.00\"\n",
      "469069-markell-10-16-22-13503282333116-_-pdf: guessed \"Total\" with score 12.04025237262249, correct \"1600\"\n",
      "431304-collect-files-35576-political-file-2012-federal: guessed \"$240.00\" with score 13.903667628765106, correct \"$85,740.00\"\n",
      "431304-collect-files-35576-political-file-2012-federal: guessed \"$240.00\" with score 13.903667628765106, correct \"$85,740.00\"\n",
      "511314-obama-1844-final_337336-1-13524183455130-_-pdf: guessed \"$207,510.00\" with score 14.112790435552597, correct \"$207,510.00\"\n",
      "469114-398590-1-13503368825844-_-pdf: guessed \"$1,870.00\" with score 13.630254223942757, correct \"$2,200.00\"\n",
      "480018-67579-1-13509285046144-_-pdf: guessed \"$165,264.71\" with score 13.607818976044655, correct \"$28,095.00\"\n",
      "431304-collect-files-35576-political-file-2012-federal: guessed \"$240.00\" with score 13.903667628765106, correct \"$85,740.00\"\n",
      "427588-collect-files-56537-political-file-2012-federal: guessed \"(WLOS)\" with score 12.800796896219254, correct \"$33,275.00\"\n",
      "511321-romney-498-final_340991-1-13524181095405-_-pdf: guessed \"$249,650.00\" with score 13.848960936069489, correct \"$249,650.00\"\n",
      "511286-334325-8-13524183157789-_-pdf: guessed \"10/29/12\" with score 13.962513208389282, correct \"$203,175.00\"\n",
      "469069-markell-10-16-22-13503282333116-_-pdf: guessed \"Total\" with score 12.04025237262249, correct \"1600\"\n",
      "480018-67579-1-13509285046144-_-pdf: guessed \"$165,264.71\" with score 13.607818976044655, correct \"$28,095.00\"\n",
      "457316-romney-for-president-wo-10-6-rev-order: guessed \"$30,500.00\" with score 14.089748442173004, correct \"$30,500.00\"\n",
      "424758-collect-files-35576-political-file-2012-federal: guessed \"$25,680.00\" with score 14.090196907520294, correct \"$25,680.00\"\n",
      "511286-334325-8-13524183157789-_-pdf: guessed \"10/29/12\" with score 13.962513208389282, correct \"$203,175.00\"\n",
      "419765-collect-files-65684-political-file-2012-federal: guessed \"$105,378.75\" with score 14.215678989887238, correct \"$123,975.00\"\n",
      "This epoch doc_val_acc: 0.4\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5267 - acc: 0.0400\n",
      "457688-romney-for-president-wo-9-12-rev-order: guessed \"$103,400.00\" with score 13.263347670435905, correct \"$103,400.00\"\n",
      "426068-collect-files-11893-political-file-2012-federal: guessed \"Total\" with score 13.180137574672699, correct \"Print\"\n",
      "480022-67469-1-13509189034926-_-pdf: guessed \"$43,259.26\" with score 12.998345077037811, correct \"$11,680.00\"\n",
      "511291-345363-0-13524181183619-_-pdf: guessed \"$85,000.00\" with score 13.447422713041306, correct \"$100,000.00\"\n",
      "470493-nrcc-ie_1019-1025-est-3390-13503489061150-_-pdf: guessed \"$15,750.00\" with score 13.411356031894684, correct \"$15,750.00\"\n",
      "426068-collect-files-11893-political-file-2012-federal: guessed \"Total\" with score 13.180137574672699, correct \"Print\"\n",
      "511324-bongino-503-final_341981-1-13524180905355-_-pdf: guessed \"$23,490.00\" with score 13.055211946368217, correct \"$23,490.00\"\n",
      "470233-arpaio-10_16722619-13504209200222-_-pdf: guessed \"$50,925.00\" with score 13.653108537197113, correct \"$50,925.00\"\n",
      "511288-342852-2-13524183124047-_-pdf: guessed \"$93,670.00\" with score 13.32388374209404, correct \"$110,200.00\"\n",
      "457688-romney-for-president-wo-9-12-rev-order: guessed \"$103,400.00\" with score 13.263347670435905, correct \"$103,400.00\"\n",
      "511296-345028-0-13524180963339-_-pdf: guessed \"$10,000.00\" with score 13.383445829153061, correct \"$1,000.00\"\n",
      "480022-67469-1-13509189034926-_-pdf: guessed \"$43,259.26\" with score 12.998345077037811, correct \"$11,680.00\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511316-obama-2051-final_341803-1-13524183386707-_-pdf: guessed \"$137,861.50\" with score 13.216709703207016, correct \"$162,190.00\"\n",
      "511318-obama-2175-final_343497-1-13524183408511-_-pdf: guessed \"$6,000.00\" with score 12.815026491880417, correct \"$180,260.00\"\n",
      "470651-obama187040-13503351151533-_-pdf: guessed \"$19,250.00\" with score 13.665321260690689, correct \"$19,250.00\"\n",
      "511318-obama-2175-final_343497-1-13524183408511-_-pdf: guessed \"$6,000.00\" with score 12.815026491880417, correct \"$180,260.00\"\n",
      "511319-rncromney-483-final_339838-1-13524180984389-_-pdf: guessed \"$1,620.00\" with score 13.297474771738052, correct \"$226,220.00\"\n",
      "442594-collect-files-73195-political-file-2012-non: guessed \"$6,350.00\" with score 13.643945574760437, correct \"$6,350.00\"\n",
      "420426-collect-files-72313-political-file-2012-non: guessed \"$9,335.00\" with score 13.666707247495651, correct \"$9,335.00\"\n",
      "419761-collect-files-65684-political-file-2012-federal: guessed \"$120,375.00\" with score 13.340027391910553, correct \"$120,375.00\"\n",
      "416945-collect-files-59441-political-file-2012-non: guessed \"WKYC\" with score 13.43424078822136, correct \"$15,900.00\"\n",
      "424793-collect-files-39738-political-file-2012-non: guessed \"$900.00\" with score 13.433066487312317, correct \"$900.00\"\n",
      "480022-67469-1-13509189034926-_-pdf: guessed \"$43,259.26\" with score 12.998345077037811, correct \"$11,680.00\"\n",
      "511281-336563-4-13524183201766-_-pdf: guessed \"$26,800.00\" with score 13.328527480363846, correct \"$26,800.00\"\n",
      "511322-romney-505-final_342216-1-13524181139554-_-pdf: guessed \"$3,000.00\" with score 12.955903053283691, correct \"$235,610.00\"\n",
      "470385-65716-1-13503969050907-_-pdf: guessed \"$6,350.00\" with score 12.939169585704803, correct \"$6,350.00\"\n",
      "This epoch doc_train_acc: 0.46153846153846156\n",
      "480018-67579-1-13509285046144-_-pdf: guessed \"$165,264.71\" with score 13.0121248960495, correct \"$28,095.00\"\n",
      "470423-obrien-oct-15-17-buy-13503963034902-_-pdf: guessed \"NOON\" with score 12.633489713072777, correct \"$1,275.00\"\n",
      "469069-markell-10-16-22-13503282333116-_-pdf: guessed \"0.00\" with score 10.833637177944183, correct \"1600\"\n",
      "419754-collect-files-65684-political-file-2012-federal: guessed \"$99,641.25\" with score 13.678880661725998, correct \"$117,225.00\"\n",
      "511295-344107-1-13524180973818-_-pdf: guessed \"$18,700.00\" with score 13.435236543416977, correct \"$22,000.00\"\n",
      "480018-67579-1-13509285046144-_-pdf: guessed \"$165,264.71\" with score 13.0121248960495, correct \"$28,095.00\"\n",
      "511283-342425-5-13524183101415-_-pdf: guessed \"$4,250.00\" with score 13.158088892698288, correct \"$50,350.00\"\n",
      "480018-67579-1-13509285046144-_-pdf: guessed \"$165,264.71\" with score 13.0121248960495, correct \"$28,095.00\"\n",
      "424758-collect-files-35576-political-file-2012-federal: guessed \"$25,680.00\" with score 13.637478560209274, correct \"$25,680.00\"\n",
      "511287-342495-1-13524183135098-_-pdf: guessed \"$22,650.00\" with score 13.53015673160553, correct \"$22,650.00\"\n",
      "511314-obama-1844-final_337336-1-13524183455130-_-pdf: guessed \"$207,510.00\" with score 13.047908246517181, correct \"$207,510.00\"\n",
      "480018-67579-1-13509285046144-_-pdf: guessed \"$165,264.71\" with score 13.0121248960495, correct \"$28,095.00\"\n",
      "427588-collect-files-56537-political-file-2012-federal: guessed \"BACHELOR\" with score 11.50555419921875, correct \"$33,275.00\"\n",
      "480018-67579-1-13509285046144-_-pdf: guessed \"$165,264.71\" with score 13.0121248960495, correct \"$28,095.00\"\n",
      "511282-339995-1-13524183255885-_-pdf: guessed \"$44,950.00\" with score 13.214190423488617, correct \"$44,950.00\"\n",
      "419754-collect-files-65684-political-file-2012-federal: guessed \"$99,641.25\" with score 13.678880661725998, correct \"$117,225.00\"\n",
      "511283-342425-5-13524183101415-_-pdf: guessed \"$4,250.00\" with score 13.158088892698288, correct \"$50,350.00\"\n",
      "431304-collect-files-35576-political-file-2012-federal: guessed \"$85,740.00\" with score 13.290673270821571, correct \"$85,740.00\"\n",
      "511315-obama-2002-final_340807-1-13524183429823-_-pdf: guessed \"$10,000.00\" with score 12.902514487504959, correct \"$169,860.00\"\n",
      "419765-collect-files-65684-political-file-2012-federal: guessed \"$105,378.75\" with score 13.595152884721756, correct \"$123,975.00\"\n",
      "431304-collect-files-35576-political-file-2012-federal: guessed \"$85,740.00\" with score 13.290673270821571, correct \"$85,740.00\"\n",
      "470423-obrien-oct-15-17-buy-13503963034902-_-pdf: guessed \"NOON\" with score 12.633489713072777, correct \"$1,275.00\"\n",
      "511282-339995-1-13524183255885-_-pdf: guessed \"$44,950.00\" with score 13.214190423488617, correct \"$44,950.00\"\n",
      "419765-collect-files-65684-political-file-2012-federal: guessed \"$105,378.75\" with score 13.595152884721756, correct \"$123,975.00\"\n",
      "419754-collect-files-65684-political-file-2012-federal: guessed \"$99,641.25\" with score 13.678880661725998, correct \"$117,225.00\"\n",
      "511321-romney-498-final_340991-1-13524181095405-_-pdf: guessed \"$249,650.00\" with score 13.093094527721405, correct \"$249,650.00\"\n",
      "This epoch doc_val_acc: 0.3076923076923077\n",
      "Epoch 3/50\n",
      " 1/10 [==>...........................] - ETA: 6s - loss: 0.4592 - acc: 0.0405"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-b35e452e7fe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m model.fit_generator(\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[0mwindowed_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1916\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1918\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "read_docs = 150 # how many docs to load, at most\n",
    "window_len = 30 # size of token sequences to train on (and network size!)\n",
    "vocab_size = 500\n",
    "token_dims = 7 # number of features per token, including token hash\n",
    "positive_fraction = 0.5\n",
    "target_thresh = 0.9 # target match scores larger than this will becomes positive labels\n",
    "epochs = 50\n",
    "batch_size=10000\n",
    "steps_per_epoch = 10\n",
    "doc_acc_sample_size = 25 # how many documents to check extraction on after each epoch\n",
    "penalize_missed = 5 # how much more a missed 1 counts than a missed 0 in output\n",
    "val_split = 0.2\n",
    "len_train = 80\n",
    "\n",
    "source_data = 'C:/Users/HP/Documents/work/DeepForm/deepform-master/source/training.csv'\n",
    "pickle_destination = 'C:/Users/HP/Documents/work/DeepForm/deepform-master/source/cached_features.p'\n",
    "\n",
    "# ---- Load data and generate features ----\n",
    "\n",
    "# Generator that reads raw training data\n",
    "# For each document, yields an array of dictionaries, each of which is a token\n",
    "def input_docs(max_docs=None):\n",
    "\tincsv = csv.DictReader(open(source_data, mode='r'))\n",
    "\t\t\n",
    "\t# Reconstruct documents by concatenating all rows with the same slug\n",
    "\tactive_slug = None\n",
    "\tdoc_rows = [] \n",
    "\tnum_docs = 0\n",
    "\n",
    "\tfor row in incsv:\t\n",
    "\t\t# throw out tokens that are too short, they won't help us\n",
    "\t\ttoken = row['token']\n",
    "\t\tif len(token) < 3:\n",
    "\t\t\tcontinue \n",
    "\n",
    "\t\tif row['slug'] != active_slug:\n",
    "\t\t\tif active_slug:\n",
    "\t\t\t\tyield doc_rows\n",
    "\t\t\t\tnum_docs += 1\n",
    "\t\t\t\tif max_docs and num_docs >= max_docs:\n",
    "\t\t\t\t\treturn\n",
    "\t\t\tdoc_rows = [row]\n",
    "\t\t\tactive_slug = row['slug']\n",
    "\t\telse:\n",
    "\t\t\tdoc_rows.append(row)\n",
    "\t\t\n",
    "\tyield doc_rows\n",
    "\n",
    "\n",
    "def is_dollar_amount(s):\n",
    "\treturn re.search(r'\\$?\\d[\\d,]+(\\.\\d\\d)?',s) != None\n",
    "\n",
    "def token_features(row, vocab_size):\n",
    "\ttokstr = row['token'].upper()\n",
    "\treturn [ hash(tokstr) % vocab_size,\n",
    "\t\t\t\t\t float(row['page']), \n",
    "\t\t\t\t\t float(row['x0']),\n",
    "\t\t\t\t\t float(row['y0']), \n",
    "\t\t\t\t\t float(len(tokstr)),\n",
    "\t\t\t\t\t float(np.mean([c.isdigit() for c in tokstr])),\n",
    "\t\t\t\t\t float(is_dollar_amount(tokstr)) ]\n",
    "\t\n",
    "# Load raw training data, create our per-token features and binary labels\t\n",
    "def load_training_data_nocache():\n",
    "\tslugs = []\n",
    "\ttoken_text = []\n",
    "\tfeatures = []\n",
    "\tlabels = []\n",
    "\tfor doc_tokens in input_docs(max_docs=read_docs):\t\n",
    "\t\tif len(doc_tokens) < window_len:\n",
    "\t\t\tcontinue # TODO pad shorter docs\n",
    "\t\t\t\n",
    "\t\t# Not training data, but used for evaluating results later\n",
    "\t\tslugs.append(doc_tokens[0]['slug']) # unique document ID, also PDF filename\n",
    "\t\ttoken_text.append([row['token'] for row in doc_tokens])\n",
    "\n",
    "\t\tfeatures.append([token_features(row, vocab_size) for row in doc_tokens])\n",
    "\t\t\n",
    "\t\t# threshold fuzzy matching score with our target field, to get binary labels \n",
    "\t\tlabels.append([(0 if float(row['gross_amount']) < target_thresh else 1) for row in doc_tokens])\n",
    "\tprint(\"Length of slugs in load_training_data_nocache = \", len(slugs))\n",
    "\treturn slugs, token_text, features, labels\n",
    "\t\n",
    "# Because generating the list of features is so expensive, we cache it on disk\n",
    "def load_training_data():\n",
    "\tif os.path.isfile(pickle_destination):\n",
    "\t\tprint('Loading training data from cache...')\n",
    "\t\tslugs, token_text, features, labels = pickle.load(open(pickle_destination, 'rb'))\n",
    "\telse:\n",
    "\t\tprint('Loading training data...')\n",
    "\t\tslugs, token_text, features, labels = load_training_data_nocache()\n",
    "\t\tprint('Saving training data to cache...')\n",
    "\t\tpickle.dump((slugs, token_text, features, labels), open(pickle_destination, 'wb'))\n",
    "\n",
    "\t# Trim the training data so we can sweep across various training data sizes\n",
    "\tprint(\"Length of slugs in load_training_data before modification = \", len(slugs))\n",
    "\tslugs = slugs[:len_train]\n",
    "\tprint(\"Length of slugs in load_training_data after modification = \", len(slugs))\n",
    "\ttoken_text = token_text[:len_train]\n",
    "\tfeatures = features[:len_train]\n",
    "\tlabels = labels[:len_train]\n",
    "\n",
    "\treturn slugs, token_text, features, labels\n",
    "\n",
    "# ---- Resample features,labels as windows ----\n",
    "\n",
    "# returns a window of tokens, labels at a random position in a random document\n",
    "def one_window_unbalanced(features, labels, window_len):\n",
    "\tdoc_idx = random.randint(0,len(features)-1)\n",
    "\tdoc_len = len(features[doc_idx])\n",
    "\ttok_idx = random.randint(0, doc_len-window_len)\n",
    "\treturn features[doc_idx][tok_idx : tok_idx+window_len], labels[doc_idx][tok_idx : tok_idx+window_len]\n",
    "\n",
    "# control the fraction of windows that include a positive label. not efficient.\n",
    "def one_window(features, labels, window_len, positive_fraction):\n",
    "\tf,l = one_window_unbalanced(features, labels, window_len)\n",
    "\tif random.random() > positive_fraction: # mostly positive examples\n",
    "\t\twhile not 1 in l:\n",
    "\t\t\tf,l = one_window_unbalanced(features, labels, window_len)\n",
    "\treturn f,l\n",
    "\n",
    "def windowed_generator(features, labels, ):\n",
    "\t# Create empty arrays to contain batch of features and labels#\n",
    "\tbatch_features = np.zeros((batch_size, window_len, token_dims))\n",
    "\tbatch_labels = np.zeros((batch_size, window_len))\n",
    "\n",
    "\twhile True:\n",
    "\t\tfor i in range(batch_size):\n",
    "\t\t\tfeatures1,labels1 = one_window(features, labels, window_len, positive_fraction)\n",
    "\t\t\tbatch_features[i,:,:] = features1\n",
    "\t\t\tbatch_labels[i,:] = labels1\n",
    "\t\tyield batch_features, batch_labels\n",
    "\n",
    "# ---- Custom loss function is basically MSE but high penalty for missing a 1 label ---\n",
    "\n",
    "def missed_token_loss(one_penalty):\n",
    "   \n",
    "\tdef _missed_token_loss(y_true, y_pred):\n",
    "\t  expected_zero = tf.cast(tf.math.equal(y_true,0), tf.float32)\n",
    "\t  s = y_pred*expected_zero\n",
    "\t  zero_loss = K.backend.mean(K.backend.square(s))\n",
    "\t  expected_one = tf.cast(tf.math.equal(y_true,1), tf.float32)\n",
    "\t  t = one_penalty*(1-y_pred)*expected_one\n",
    "\t  one_loss = K.backend.mean(K.backend.square(t))\n",
    "\t  return zero_loss + one_loss\n",
    "\n",
    "\treturn _missed_token_loss # closes over one_penalty\n",
    "\n",
    "# --- Specify network ---\n",
    "\n",
    "def create_model():\n",
    "\tindata = Input((window_len, token_dims))\n",
    "\n",
    "\t# split into the hash and the rest of the token features, embed hash as one-hot, then merge\n",
    "\ttok_hash = Lambda( lambda x: squeeze(tf.slice(x, (0,0,0), (-1,-1,1)),axis=2))(indata)\n",
    "\ttok_features = Lambda( lambda x: tf.slice(x, (0,0,1), (-1,-1,-1)))(indata)\n",
    "\tembed = Embedding(vocab_size, 32)(tok_hash)\n",
    "\tmerged = concatenate([embed, tok_features], axis=2)\n",
    "\n",
    "\tf = Flatten()(merged)\n",
    "\td1 = Dense(window_len*token_dims*5, activation='sigmoid')(f)\n",
    "\td2 = Dropout(0.3)(d1)\n",
    "\td3 = Dense(window_len*token_dims, activation='sigmoid')(d2)\n",
    "\td4 = Dropout(0.3)(d3)\n",
    "\td5 = Dense(window_len, activation='elu')(d4)\n",
    "\n",
    "\tmodel = Model(inputs=[indata], outputs=[d5])\n",
    "\tmodel.compile(\n",
    "\t\toptimizer='adam', \n",
    "\t\tloss=missed_token_loss(penalize_missed), \n",
    "\t\tmetrics=['acc'])\n",
    "\n",
    "\treturn model\n",
    "\n",
    "# --- Predict ---\n",
    "# Our network is windowed, so we have to aggregate windows to get a final score\n",
    "\n",
    "# Returns vector of token scores\n",
    "def predict_scores(model, features, window_len):\n",
    "\tdoc_len = len(features)\n",
    "\tnum_windows = doc_len-window_len\n",
    "\n",
    "\twindowed_features = np.array([features[i:i+window_len] for i in range(num_windows)])\n",
    "\twindow_scores = model.predict(windowed_features)\n",
    "\n",
    "\tscores = np.zeros(doc_len)\n",
    "\tfor i in range(num_windows):\n",
    "\t\tscores[i:i+window_len] += window_scores[i] # would max work better than sum?\n",
    "\treturn scores\n",
    "\n",
    "# returns text, score of best answer\n",
    "def predict_answer(model, features, token_text, window_len):\n",
    "\tscores = predict_scores(model, features, window_len)\n",
    "\tbest_score_idx = np.argmax(scores)\n",
    "\tbest_score_text = token_text[best_score_idx]\n",
    "\treturn best_score_text, scores[best_score_idx]\n",
    "\n",
    "# returns text of correct answer,\n",
    "def correct_answer(features, labels, token_text):\n",
    "\tanswer_idx = np.argmax(labels)\n",
    "\tanswer_text = token_text[answer_idx]\n",
    "\treturn answer_text\n",
    "\n",
    "# Calculate accuracy of answer extraction over num_to_test docs, print diagnostics while we do so\n",
    "def compute_accuracy(model, window_len, slugs, token_text, features, labels, num_to_test):\n",
    "\tacc = 0.0\n",
    "\tfor i in range(num_to_test):\n",
    "\t\tdoc_idx = random.randint(0, len(slugs)-1)\n",
    "\t\tpredict_text, predict_score = predict_answer(model, features[doc_idx], token_text[doc_idx], window_len)\n",
    "\t\tanswer_text = correct_answer(features[doc_idx], labels[doc_idx], token_text[doc_idx])\n",
    "\t\tprint(f'{slugs[doc_idx]}: guessed \"{predict_text}\" with score {predict_score}, correct \"{answer_text}\"')\n",
    "\t\tif predict_text==answer_text:\n",
    "\t\t\tacc+=1\n",
    "\treturn acc/num_to_test\n",
    "\n",
    "\n",
    "# ---- Custom callback to log document-level accuracy ----\n",
    "\n",
    "class DocAccCallback(K.callbacks.Callback):\n",
    "\tdef __init__(self, window_len, slugs, token_text, features, labels, num_to_test, logname):\n",
    "\t\tself.window_len = window_len\n",
    "\t\tself.slugs = slugs\n",
    "\t\tself.token_text = token_text\n",
    "\t\tself.features = features\n",
    "\t\tself.labels = labels\n",
    "\t\tself.num_to_test = num_to_test\n",
    "\t\tself.logname = logname\n",
    "\n",
    "\tdef on_epoch_end(self, epoch, logs):\n",
    "\t\tacc = compute_accuracy(self.model,\n",
    "\t\t\tself.window_len,\n",
    "\t\t\tself.slugs,\n",
    "\t\t\tself.token_text,\n",
    "\t\t\tself.features,\n",
    "\t\t\tself.labels,\n",
    "\t\t\tself.num_to_test+epoch)  # test more docs later in training, for more precise acc\n",
    "\t\tprint(f'This epoch {self.logname}: {acc}')\n",
    "\t\t#wandb.log({self.logname:acc})\n",
    "\n",
    "\n",
    "# --- MAIN ----\n",
    "\n",
    "#print('uration:')\n",
    "#print()\n",
    "\n",
    "slugs, token_text, features, labels = load_training_data()\n",
    "print(f'Loaded {len(features)}')\n",
    "max_length = max([len(x) for x in labels])\n",
    "print(f'Max document size {max_length}')\n",
    "avg_length = sum([len(x) for x in labels])/len(labels)\n",
    "print(f'Average document size {avg_length}')\n",
    "\n",
    "# split into train and test\n",
    "slugs_train = []\n",
    "token_text_train = []\n",
    "features_train = []\n",
    "labels_train = []\n",
    "slugs_val = []\n",
    "token_text_val = []\n",
    "features_val = []\n",
    "labels_val = []\n",
    "for i in range(len(features)):\n",
    "\tif random.random() < val_split:\n",
    "\t\tslugs_val.append(slugs[i])\n",
    "\t\ttoken_text_val.append(token_text[i])\n",
    "\t\tfeatures_val.append(features[i])\n",
    "\t\tlabels_val.append(labels[i])\n",
    "\telse:\n",
    "\t\tslugs_train.append(slugs[i])\n",
    "\t\ttoken_text_train.append(token_text[i])\t\t\n",
    "\t\tfeatures_train.append(features[i])\n",
    "\t\tlabels_train.append(labels[i])\n",
    "\n",
    "print(f'Training on {len(features_train)}, validating on {len(features_val)}')\n",
    "\n",
    "model = create_model()\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "\twindowed_generator(features_train, labels_train, ),\n",
    "\tsteps_per_epoch=steps_per_epoch,\n",
    "\tepochs=epochs,\n",
    "\tcallbacks=[ \n",
    "\t\t#WandbCallback(),\n",
    "\t\tDocAccCallback(\twindow_len, \n",
    "\t\t\t\t\t\t\t\t\t\tslugs_train, \n",
    "\t\t\t\t\t\t\t\t\t\ttoken_text_train, \n",
    "\t\t\t\t\t\t\t\t\t\tfeatures_train, \n",
    "\t\t\t\t\t\t\t\t\t\tlabels_train, \n",
    "\t\t\t\t\t\t\t\t\t\tdoc_acc_sample_size,\n",
    "\t\t\t\t\t\t\t\t\t\t'doc_train_acc'),\n",
    "\t\tDocAccCallback(\twindow_len, \n",
    "\t\t\t\t\t\t\t\t\t\tslugs_val, \n",
    "\t\t\t\t\t\t\t\t\t\ttoken_text_val, \n",
    "\t\t\t\t\t\t\t\t\t\tfeatures_val, \n",
    "\t\t\t\t\t\t\t\t\t\tlabels_val, \n",
    "\t\t\t\t\t\t\t\t\t\tdoc_acc_sample_size,\n",
    "\t\t\t\t\t\t\t\t\t\t'doc_val_acc')\n",
    "\t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131860b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
